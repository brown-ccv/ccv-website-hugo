---
title: High-Performance Computing (HPC)
date: 2019-01-22 18:29:23 +0000
category: Computing
icon: server2
lead: CCV's research computing cluster has more than 500 compute nodes, including
  both CPU and GPU nodes, and a GPFS parallel filesystem.
haas: true

---
The high-performance computing (HPC) resources at CCV equip the Brown research community with the tools they need to perform complex numerical simulations, modeling, and data analysis. Oscar, CCV's primary research computing cluster, consists of more than 500 multi-core nodes sharing a high-performance interconnect and file system. 

# Oscar Technical Specifications

{{% table c="striped" hover="false" w="100" head="dark" %}}

| Compute Nodes | 472 |
| GPU Nodes | 35 |
| Login Nodes | 2 |
| Large-Memory Nodes (512 GB) | 2 |
| Total CPU Cores | 9612 |
| Total GPUs | 194 |
| Total Storage (GPFS Filesystem) | >1 PB |
| OS | RedHat EL 7.3 (Linux) |
| Job Scheduler | Slurm Workload Manager |

{{% /table %}}

> † Free exploratory accounts are available to all tenure-track faculty and PIs at Brown. Students and researchers may also obtain an exploratory account with written permission from their advisor or PI. Exploratory accounts have a 16-core limit per user, with a per-job limit of 46,100 core-minutes.

> ‡The maximum number of cores and duration may change based on cluster utilization. Priority accounts each have a QOS allowing up to 208 cores, 1TB memory, and total running job wallclock of 998,400 core-minutes. This allows a 208-core job to run for 80 hours, a 104-core job to run for 160 hours, or 208 1-core jobs to run for 80 hours.

{{< account_form >}}